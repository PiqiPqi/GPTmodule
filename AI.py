import streamlit as st
from langchain.chains.conversation.base import ConversationChain
from langchain.memory import ConversationBufferMemory
from langchain_openai import ChatOpenAI
import streamlit.components.v1 as components

# è®¾ç½®é¡µé¢é…ç½®
st.set_page_config(
    page_title="WideSeek",
    page_icon="ğŸ¤–",
    layout="wide",
    initial_sidebar_state="expanded"
)

# å…¨å±€æ ·å¼è®¾ç½®
st.markdown("""
<style>
    .main .block-container {
        max-width: 90%;
        padding-top: 1rem;
    }
    .css-12oz5g7 {
        box-shadow: 0 0 10px rgba(0,0,0,0.1);
    }
    .reportview-container {
        background-color: #f5f7fa;
    }
    .sidebar .sidebar-content {
        background-color: #ffffff;
        padding: 1rem;
        border-radius: 10px;
        box-shadow: 0 0 10px rgba(0,0,0,0.1);
    }
</style>
""", unsafe_allow_html=True)

# åˆå§‹åŒ–ä¼šè¯çŠ¶æ€
if 'messages' not in st.session_state:
    st.session_state['messages'] = [{'role': 'ai', 'content': 'ä½ å¥½ä¸»äººï¼Œæˆ‘æ˜¯ä½ çš„AIåŠ©æ‰‹ï¼Œæˆ‘å«å°ç¾ï¼Œå¾ˆé«˜å…´ä¸ºä½ æœåŠ¡ï¼'}]
    st.session_state['memory'] = ConversationBufferMemory(return_message=True)
    st.session_state['API_KEY'] = ''
    st.session_state['model_name'] = 'gpt-4o-mini'
    st.session_state['temperature'] = 0.7
    st.session_state['max_tokens'] = 1000


def get_ai_response(user_prompt):
    model = ChatOpenAI(
        model=st.session_state['model_name'],
        temperature=st.session_state['temperature'],
        max_tokens=st.session_state['max_tokens'],
        api_key=st.session_state['API_KEY'],
        base_url='https://twapi.openai-hk.com/v1'
    )
    chain = ConversationChain(llm=model, memory=st.session_state['memory'])
    return chain.invoke({'input': user_prompt})['response']


# ä¾§è¾¹æ å†…å®¹
with st.sidebar:
    st.markdown("<h2 style='color: #2c3e50;'>å°ç¾AIåŠ©æ‰‹è®¾ç½®</h2>", unsafe_allow_html=True)

    # APIå¯†é’¥è¾“å…¥
    api_key = st.text_input(
        'OpenAI APIå¯†é’¥:',
        type='password',
        value=st.session_state['API_KEY'] if 'API_KEY' in st.session_state else '',
        help="è¯·è¾“å…¥æ‚¨çš„OpenAI APIå¯†é’¥ä»¥ä½¿ç”¨æœåŠ¡"
    )
    st.session_state['API_KEY'] = api_key

    # æ¨¡å‹é€‰æ‹©
    st.subheader("æ¨¡å‹è®¾ç½®")
    model_name = st.selectbox(
        'é€‰æ‹©AIæ¨¡å‹:',
        ('gpt-4o-mini', 'gpt-3.5-turbo', 'gpt-4'),
        index=0,
        help="é€‰æ‹©æ‚¨æƒ³è¦ä½¿ç”¨çš„AIæ¨¡å‹"
    )
    st.session_state['model_name'] = model_name

    # å‚æ•°è°ƒæ•´
    st.subheader("ç”Ÿæˆå‚æ•°")
    col1, col2 = st.columns(2)
    with col1:
        temperature = st.slider(
            'åˆ›é€ æ€§:',
            min_value=0.0,
            max_value=2.0,
            value=st.session_state['temperature'] if 'temperature' in st.session_state else 0.7,
            step=0.1,
            help="æ§åˆ¶AIå›ç­”çš„åˆ›é€ æ€§ï¼Œå€¼è¶Šé«˜å›ç­”è¶Šéšæœº"
        )
    with col2:
        max_tokens = st.slider(
            'æœ€å¤§é•¿åº¦:',
            min_value=100,
            max_value=4000,
            value=st.session_state['max_tokens'] if 'max_tokens' in st.session_state else 1000,
            step=100,
            help="æ§åˆ¶AIå›ç­”çš„æœ€å¤§é•¿åº¦"
        )
    st.session_state['temperature'] = temperature
    st.session_state['max_tokens'] = max_tokens

    # æ¸…é™¤å¯¹è¯å†å²
    if st.button('æ¸…é™¤å¯¹è¯å†å²', key='clear_history'):
        st.session_state['messages'] = [{'role': 'ai', 'content': 'ä½ å¥½ä¸»äººï¼Œæˆ‘æ˜¯ä½ çš„AIåŠ©æ‰‹ï¼Œæˆ‘å«å°ç¾ï¼Œå¾ˆé«˜å…´ä¸ºä½ æœåŠ¡ï¼'}]
        st.session_state['memory'].clear()
        st.experimental_rerun()

    # å¸®åŠ©ä¿¡æ¯
    st.markdown("""
    <div style="margin-top: 2rem; padding: 1rem; background-color: #f8f9fa; border-radius: 5px;">
        <h4 style='color: #2c3e50;'>ä½¿ç”¨è¯´æ˜</h4>
        <ol style='color: #555;'>
            <li>è¾“å…¥æ‚¨çš„OpenAI APIå¯†é’¥</li>
            <li>é€‰æ‹©æ‚¨æƒ³è¦ä½¿ç”¨çš„AIæ¨¡å‹</li>
            <li>è°ƒæ•´ç”Ÿæˆå‚æ•°ï¼ˆå¯é€‰ï¼‰</li>
            <li>åœ¨ä¸»ç•Œé¢å¼€å§‹ä¸AIå¯¹è¯</li>
        </ol>
        <p style='color: #7f8c8d; font-size: 0.8rem;'>é‡åˆ°é—®é¢˜ï¼Ÿè¯·æ£€æŸ¥APIå¯†é’¥æ˜¯å¦æ­£ç¡®</p>
    </div>
    """, unsafe_allow_html=True)

# ä¸»ç•Œé¢
st.markdown("<h1 style='color: #2c3e50;'>ğŸ¤– å°ç¾AIåŠ©æ‰‹</h1>", unsafe_allow_html=True)

# æ˜¾ç¤ºå¯¹è¯å†å²
if st.session_state['messages']:
    for message in st.session_state['messages']:
        role, content = message['role'], message['content']
        if role == 'human':
            st.chat_message("user").write(content)
        else:
            st.chat_message("assistant").write(content)

# ç”¨æˆ·è¾“å…¥
user_input = st.chat_input("è¯·è¾“å…¥ä½ çš„é—®é¢˜...")
if user_input:
    if not st.session_state['API_KEY']:
        st.info('è¯·å…ˆåœ¨ä¾§è¾¹æ è¾“å…¥æ‚¨çš„OpenAI APIå¯†é’¥ï¼')
        st.stop()

    # æ˜¾ç¤ºç”¨æˆ·æ¶ˆæ¯
    st.chat_message("user").write(user_input)
    st.session_state['messages'].append({'role': 'human', 'content': user_input})

    # è·å–AIå“åº”
    with st.spinner('å°ç¾æ­£åœ¨æ€è€ƒï¼Œè¯·ç¨å€™...'):
        try:
            resp_from_ai = get_ai_response(user_input)
            st.chat_message("assistant").write(resp_from_ai)
            st.session_state['messages'].append({'role': 'ai', 'content': resp_from_ai})
        except Exception as e:
            st.error(f"å‘ç”Ÿé”™è¯¯: {str(e)}")
            st.session_state['messages'].append({'role': 'ai', 'content': f"æŠ±æ­‰ï¼Œæˆ‘é‡åˆ°äº†ä¸€ä¸ªé”™è¯¯: {str(e)}"})